from fastapi import FastAPI
from pydantic import BaseModel
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F

app = FastAPI()

# âœ… ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ (KcELECTRA)
tokenizer = AutoTokenizer.from_pretrained("beomi/KcELECTRA-base")
model = AutoModelForSequenceClassification.from_pretrained("beomi/KcELECTRA-base")

labels = ["very_pos", "pos", "neu", "neg", "very_neg"]
emojis = ["ğŸ¤©", "ğŸ˜Š", "ğŸ˜", "ğŸ™", "ğŸ˜¡"]

# âœ… ê°ì„± ë¶„ì„ ìš”ì²­ êµ¬ì¡°
class ReviewInput(BaseModel):
    text: str
    restaurant_id: str
    source: str
    user_id: str | None = None

# âœ… í‚¤ì›Œë“œ í™•ì¥ ìš”ì²­ êµ¬ì¡°
class KeywordInput(BaseModel):
    keyword: str

# âœ… ì„ì‹œ í•˜ë“œì½”ë”©ëœ ì˜ë¯¸ ì—°ê´€ í‚¤ì›Œë“œ ë§¤í•‘
keyword_mapping = {
    "ë‚ ì”¨ëŠ” ë§‘ìŒ": ["ë‚ ì”¨", "ë§‘ìŒ", "ë”ì›€", "ì‹œì›í•¨"],
    "ë§¤ì½¤í•œ ë§›": ["ë§¤ìš´ë§›", "ê³ ì¶”", "ì–¼í°", "ë¶ˆë§›"],
    "ëˆˆ ì˜¤ëŠ” ë‚ ": ["ëˆˆ", "ì¶”ì›€", "êµ­ë¬¼", "ë”°ëœ»í•¨"],
    "ë°”ë‹¤ ë³´ë©´ì„œ ë¨¹ê¸° ì¢‹ì€": ["ë°”ë‹¤", "ë·°ë§›ì§‘", "í•´ì‚°ë¬¼", "ê´‘ì•ˆë¦¬"],
}

# âœ… ê°ì„± ë¶„ì„ API
@app.post("/analyze")
def analyze(input: ReviewInput):
    inputs = tokenizer(input.text, return_tensors="pt", truncation=True)
    with torch.no_grad():
        logits = model(**inputs).logits
        probs = F.softmax(logits / 1.2, dim=-1).tolist()[0]

    top_idx = int(torch.argmax(torch.tensor(probs)))
    return {
        "restaurant_id": input.restaurant_id,
        "labels": labels,
        "probs": probs,
        "top_label": labels[top_idx],
        "top_prob": probs[top_idx],
        "ui": {
            "emoji": emojis[top_idx],
            "percent": round(probs[top_idx] * 100)
        }
    }

# âœ… í‚¤ì›Œë“œ í™•ì¥ API
@app.post("/expand_keywords")
def expand_keywords(req: KeywordInput):
    input_kw = req.keyword.strip()
    expanded = keyword_mapping.get(input_kw, [input_kw])  # ì—†ìœ¼ë©´ ì›ë¬¸ ê·¸ëŒ€ë¡œ
    return { "keywords": expanded }
